---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-SynXR Lab'></span>
The **SynXR (Synesthesia XR) Lab** explores Human-Computer Interaction (HCI) at the intersection of synesthetic experiences and performance art in extended reality (XR) environments. Through an interdisciplinary approach combining Design, Computer Science, Psychology, and Performing Arts, the lab investigates how multi-sensory integration and cross-reality interactions can enhance human perception, creativity, and artistic expression in digital spaces.

<span class='anchor' id='about-me'></span>

Hi, I am **Shuo Yan**, an Associate Professor at [School of New Media Art & Design](https://art.buaa.edu.cn/index.htm) / [State Key Laboratory of Virtual Reality Technology and Systems](https://vrlab.buaa.edu.cn/index.htm) in [Beihang University](https://www.buaa.edu.cn/). I received my Ph.D. in Intelligent Digital Performance from Beijing Institute of Technology, during which I was a visiting Ph.D. student in the Fluid Interfaces at [MIT Media Lab](https://www.media.mit.edu/). I received the Outstanding Doctoral Dissertation Award from China Simulation Federation, the Outstanding Graduation Project Supervisor Award from Beijing Higher Education Institutions, and the Xiaomi Young Scholar Award.

My research focuses on creating novel immersive XR experiences. I have published more than 30 papers and 20 artworks at the top international HCI/XR conferences.

â­ Looking for highly motivated students and research interns. æ‹›æ”¶ç¡•å£«ç”ŸåŠæš‘æœŸ/æ—¥å¸¸å­¦ç”Ÿç§‘ç ”ï¼Œæœ‰æ„è¯·è”ç³»æœ¬äººé‚®ç®±

# ğŸ‘©ğŸ»â€ğŸ« Teaching
- VR Interaction Design è™šæ‹Ÿç°å®äº¤äº’è®¾è®¡ï¼ˆæœ¬ç§‘ï¼‰
- Information Visualization Design ä¿¡æ¯å¯è§†åŒ–è®¾è®¡ï¼ˆæœ¬ç§‘ï¼‰
- Human-Computer Interaction and User Experience Design äººæœºäº¤äº’ä¸ç”¨æˆ·ä½“éªŒè®¾è®¡ï¼ˆç ”ç©¶ç”Ÿï¼‰
- Fundamentals of Digital Media Design æ•°å­—åª’ä½“è®¾è®¡åŸºç¡€ï¼ˆæœ¬ç§‘ï¼‰

# ğŸ§ª Research Foundations
- Humanities and Social Science Fund of Ministry of Education of China, Project: **XR-Based Intelligent Performance Perception Generation and Interaction Collaboration**(2022-2025) æ•™è‚²éƒ¨äººæ–‡ç¤¾ä¼šç§‘å­¦åŸºé‡‘è§„åˆ’é¡¹ç›®
- National Natural Science Foundation of China, Project: **Research on Affective Evaluation and Content-Based Adaptive Feedback for Intelligent Interactive Performance from Audience Perception**(2019-2021) å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é’å¹´é¡¹ç›®
- China National Arts Fund, Project: **Construction of Digital Promotion Platform for Intangible Culture Heritage (ICH) â€˜Hua erâ€™** (2018-2020) å›½å®¶è‰ºæœ¯åŸºé‡‘ä¼ æ’­æ¨å¹¿é¡¹ç›®
- National Key Research and Development Program of China, Project: **Yunnan Minority Dance Digital Performance Creativity and Display System Based on VR** (2019-2024) äº‘å—çœç§‘æŠ€å…é‡ç‚¹ç ”å‘é¡¹ç›®ï¼ˆå­è¯¾é¢˜ï¼‰
- Independent Project of the State Key Laboratory of Virtual Reality Technology and Systems, Project: **Research on Innovative Design of Immersive Performance under Human-AI Collaboration**(2024-2026) è™šæ‹Ÿç°å®æŠ€æœ¯ä¸ç³»ç»Ÿå…¨å›½é‡ç‚¹å®éªŒå®¤è‡ªä¸»è¯¾é¢˜

# ğŸ”” News 
- Dec, 2025 Â· SIGGRAPH ASIA Conference, ğŸ“HongKong, China
- Nov, 2025 Â· ICXR Conference <a href="https://icxr.net/2025/callForXRGallery.html">**XR Gallery Chair**</a>, ğŸ“Qingdao, China
- May, 2025 Â· CHI Conference, ğŸ“Yokohama, Japan

# ğŸ“– Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge2">IASDR 2025</div><div class="badge2">IASDR 2025</div><img src='images/matrix sheet.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**From Body to Interface: Co-design Gesture-based Interactions with Experts for Immersive Experiences**](https://iasdr2025.org/)

Zixiao Liu, **Shuo Yan**, Haiyan Jiang, Fengyi Yan and Henry Been-Lirn Duh

<a href="https://iasdr2025.org/" style="text-decoration: none; color: #00369F;">**To be published**</a>
- We developed a co-design framework and apply it to a foot-based interaction project exploring habitual foot actions as natural inputs for virtual-physical switching experience.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge2">IASDR 2025</div><div class="badge2">IASDR 2025</div><img src='images/mr.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Exploring and Co-Designing Typical Collaborative Scenarios in Mixed Reality: A Role-Based Approach**](https://iasdr2025.org/)

Fengyi Yan, **Shuo Yan**, Wensi Dai, Likun Zhao and Zixiao Liu

<a href="https://iasdr2025.org/" style="text-decoration: none; color: #00369F;">**To be published**</a>
- We proposed a comprehensive Role Interpretation Framework based on three core interpersonal dimensionsâ€”Dominance, Sociability, and Task Orientationâ€”to systematically capture and explain user roles in MR collaboration. 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CHI 2025</div><div class="badge">CHI 2025</div><img src='images/P1.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**"If My Apple Can Talk": Exploring the Use of Everyday Objects as Personalized AI Agents in Mixed Reality**](https://dl.acm.org/doi/full/10.1145/3706599.3720253)

Yu Wang, Yulu Lu, **Shuo Yan**, Xukun Shen

<a href="https://www.youtube.com/watch?v=FvPCVOcMXtc" style="text-decoration: none; color: #00369F;">**Video**</a>
- We developed the MyAIPal prototype system, which enables users to interact with AI agents of personalized everyday objects through voice dialogue and natural behaviors. 
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge1">ISMAR 2024</div><img src='images/beyondreality.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Beyond Realities: Designing Cross-Reality Interactions in the Immersive Narrative Experience**](https://ieeexplore.ieee.org/document/10765257)

Zixiao Liu, **Shuo Yan**, Wenjie He, Xiaomeng Wan, Xukun Shen

<a href="https://youtu.be/O6Cn66E263Y?si=XQUt2BcsvsAuqsQf" style="text-decoration: none; color: #00369F;">**Video**</a>
- We designed an immersive narrative â€œBeyond Realitiesâ€, and implemented four CR interactions in it: Portal Passthrough, Virtual Guidance, Object Passthrough, and Bystander Avatar.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge3">IEEE VIS 2024</div><img src='images/metamood.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**MetaMood: An AI-based Shared Emotion Visualisation in Immersive Healing Spaces**](https://ieeevis.org/year/2024/program/poster_v-vis-posters-1034.html)

Fengyi Yan, Siyu Luo, **Shuo Yan**, Xukun Shen

[**Video**](https://www.youtube.com/watch?v=5cG9H03thnM) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Metamood is an AI visualization system that automatically generates visual expressions of emotions in group art therapy.
</div>
</div>




<div class='paper-box'><div class='paper-box-image'><div><div class="badge3">SIGGRAPH ASIA 2023</div><img src='images/achi.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**â€œAchi Mukua Experience Spaceâ€ â€”â€” A Multi-Player Immersive Experience of Yunnan ICH Dance**](https://dl.acm.org/doi/10.1145/3610591.3616431)

Siyu Luo, **Shuo Yan**

<a href="https://www.youtube.com/watch?v=HYASrRvVG4E" style="text-decoration: none; color: #00369F;">**Video**</a>
- We develops design methods for ICH dance that combine social presence, collaborative multiplayer interaction, and emotional feedback to enable the co-creation immersive experiences.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CHI 2023</div><img src='images/child.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**NoPhobiar: Designing A VR Game to Prevent Childhood Dark Phobia with Children and Stakeholders**](https://dl.acm.org/doi/10.1145/3544549.3585733)

XinyiÂ Su, **ShuoÂ Yan**

<a href="https://www.youtube.com/watch?v=bero8nW8BW8" style="text-decoration: none; color: #00369F;">**Video**</a>
- We developed a VR game for treating dark phobia in children aged 4-6 through participatory research involving children and stakeholders to identify design requirements.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge1">IEEE VR 2023</div><img src='images/cohand.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**A Comparison of Gesture-based Interaction and Controller-based Interaction for External Users in Co-located Asymmetric Virtual Reality**](https://ieeexplore.ieee.org/document/10108892)

Yuetong Zhao, **Shuo Yan**, Xuanmiao Zhang, Xukun Shen

<a href="https://www.youtube.com/watch?v=Zr812Xxezfs" style="text-decoration: none; color: #00369F;">**Video**</a>
- We designed a wearable gesture-based interface for external users in two main asymmetric VR scenarios: (1) Object Transition, (2) Collaborative Game.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CHI 2022</div><img src='images/huaer.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Generating Embodied Storytelling and Interactive Experience of China Intangible Cultural Heritage â€œHua'erâ€ in Virtual Reality**](https://dl.acm.org/doi/10.1145/3491101.3519761)

Zixiao Liu, **Shuo Yan**, Yu Lu, Yuetong Zhao

<a href="https://www.youtube.com/watch?v=Zr812Xxezfs" style="text-decoration: none; color: #00369F;">**Video**</a>
- We proposed "Hua'er and the Youth," an interactive VR system integrating virtual avatar, participatory performance, and game-based knowledge acquisition for experiencing Hua'er performance.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge1">ISMAR 2022</div><img src='images/eeg.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Effects of Augmenting Real-Time Biofeedback in An Immersive VR Performance**](https://ieeexplore.ieee.org/document/9974500)

Saixi Ge, Siyu Luo, **Shuo Yan**, Xukun Shen

<a href="https://www.youtube.com/watch?v=Zr812Xxezfs" style="text-decoration: none; color: #00369F;">**Video**</a>
- We proposed a support system to investigate how performer's heart rate (HR) and audience's electroencephalogram (EEG) visualizations, and the corresponding auditory feedback, influence audience's sense of perception, immersion, and the narrative understanding.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CHI 2021</div><img src='images/perform.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Performing with Me: Enhancing Audience-Performer Interaction in An Immersive Virtual Play**](https://dl.acm.org/doi/10.1145/3411763.3451686)

**Shuo Yan**, Saixi Ge, Jinhui Wang, Xukun Shen

<a href="https://www.youtube.com/watch?v=Zr812Xxezfs" style="text-decoration: none; color: #00369F;">**Video**</a>
- We presented a novel immersive theater-based approach for enhancing audience-performer interaction in virtual plays through individual-based, scenario-based, and narrative-based interactions.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IUI 2016</div><img src='images/brain.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Enhancing audience engagement in performing arts through an adaptive virtual environment with a brain-computer interface**](https://dl.acm.org/doi/10.1145/2856767.2856768)

**Shuo Yan**, GangYi Ding, Hongsong Li, Ningxiao Sun, Yufeng Wu, Zheng Guan, Longfei Zhang, Tianyu Huang

<a href="https://www.youtube.com/watch?v=_nPOLL21Jh0" style="text-decoration: none; color: #00369F;">**Video**</a>
- We developed a real-time EEG-based system that monitors audience engagement during immersive theatre performances and triggers adaptive performing cues when engagement decreases, with experimental results from 48 participants demonstrating its effectiveness in regaining audience engagement.
</div>
</div>





# ğŸ˜ˆ XR Demos and Artworks

<div class='paper-box'><div class='paper-box-image'><div><div class="badge3">SIGGRAPH ASIA 2025</div><img src='images/hand.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Hands in Bloom: An Auditory-Accessible Immersive Experience Based on Chinese Sign Language Recognition and Gesture Tracking**](https://asia.siggraph.org/2025/)

Zhu Zhu, **Shuo Yan**

[**Video**](https://www.youtube.com/watch?v=dwbTcSVA9vo) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
<a href="https://asia.siggraph.org/2025/" style="text-decoration: none; color: #00369F;">**To be published**</a>
- This project integrates Chinese Sign Language into immersive interaction, enhancing expressiveness and inclusivity while enabling barrier-free communication that bridges Deaf and hearing communities beyond natural gestures and instruction.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge3">SIGGRAPH ASIA 2025</div><img src='images/bamboo.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Bamboo Rhyme Craft: Immersive VR Bamboo Weaving through Coordinated Bimanual Gesture Interaction**](https://asia.siggraph.org/2025/)

Chenyue Zheng, Yaxuan Zhao, Runxin Guo, **Shuo Yan**

[**Video**](https://www.youtube.com/watch?v=uH990ha-o50) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
<a href="https://asia.siggraph.org/2025/" style="text-decoration: none; color: #00369F;">**To be published**</a>
- Immersive VR with coordinated bimanual gesture interaction revives traditional bamboo weaving, blending cultural heritage with engaging, hands-on experiences to promote, preserve, and creatively reinterpret intangible traditions for wider audiences.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge3">SIGGRAPH ASIA 2023</div><img src='images/dongba.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**â€œDongba Script Character Construction Spaceâ€: VR science-based interactive experience of pictographs in intangible cultural heritage**](https://dl.acm.org/doi/10.1145/3610549.3614604)

Yulu Lu, Wensi Dai, **Shuo Yan**

[**Video**](https://www.youtube.com/watch?v=HYASrRvVG4E) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
-  This work provided an immersive virtual reality experience based on the Dongba script of the Naxi people in Yunnan Province, China.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge3">SIGGRAPH ASIA 2022</div><img src='images/dancedrum.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**â€œDance of Drumsâ€: An Interactive Installation of ICH Dance Representation Through the Combination of Virtual and Reality**](https://dl.acm.org/doi/10.1145/3610549.3614604)

Zixiao Liu, **Shuo Yan**

[**Video**](https://www.youtube.com/watch?v=HYASrRvVG4E) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
-  This work provided an immersive virtual reality experience based on the Dongba script of the Naxi people in Yunnan Province, China.
</div>
</div>
















# ğŸ† Honors and Awards
- 2024 Mentor Award
- 2023 Winner, Second Prize of Outstanding Innovation Cases of Aesthetic Education in Beijing Universitiesï¼ŒBeijing Education Commission
- 2023 Mentor Award, BUAA Excellent Master's Thesis BUAA
- 2022 Grant, $14000 Research Funding from Xiaomi Youth Scholarship Xiaomi
- 2022 Grant, $7000 Research Funding from Social Science Youth Scholarship BUAA
- 2021-2022 Mentor Award, Outstanding Undergraduate Graduation Design (Thesis)ï¼ŒBeijing Education Commission
- 2019 Winner, Third Prize of "Teaching Design" in the 7th National Collegiate and Universities Digital Art and Design Competition Ministry of Industry and Information Technology (MIIT)
- 2017 Winner, Outstanding Doctoral Dissertation Award of China Simulation Federation(CSF)
- 2015 Fellowship, National PhD Scholarship in China Ministry of Education of China

# ğŸ“š Educations
- 2013.09 - 2014.09, Visiting PhD Student, MIT Media Lab. 
- 2012.09 - 2017.06, PhD in Software Engineering, Intelligent Digital Performance, BEIJING INSTITUTE OF TECHNOLOGY 
- 2006.09 - 2010.06, Bachelor of DESIGN, Industrial Design / Business Administration (Double Degree), BEIJING INSTITUTE OF TECHNOLOGY

# ğŸ’¬ Invited Talks
- 2025.11, <a href="https://mp.weixin.qq.com/s/Im6Z4NIer50IrrRqCpHwpA" style="text-decoration: none; color: #00369F;">**Research on Innovative Design of Human-Computer Collaborative Intelligent Performance**</a>, , Dance Research Institute, China National Academy of Arts.  
- 2019.09, TEDxChengdu

