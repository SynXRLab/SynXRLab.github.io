---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-SynXR Lab'></span>
The **SynXR (Synesthesia XR) Lab** explores Human-Computer Interaction (HCI) at the intersection of synesthetic experiences and performance art in extended reality (XR) environments. Through an interdisciplinary approach combining Design, Computer Science, Psychology, and Performing Arts, the lab investigates how multi-sensory integration and cross-reality interactions can enhance human perception, creativity, and artistic expression in digital spaces.

<span class='anchor' id='about-me'></span>

Hi, I am **Shuo Yan**, an Associate Professor at [School of New Media Art & Design](https://art.buaa.edu.cn/index.htm) / [State Key Laboratory of Virtual Reality Technology and Systems](https://vrlab.buaa.edu.cn/index.htm) in [Beihang University](https://www.buaa.edu.cn/). I received my Ph.D. in Intelligent Digital Performance from Beijing Institute of Technology, during which I was a visiting Ph.D. student in the Fluid Interfaces at [MIT Media Lab](https://www.media.mit.edu/). I received the Outstanding Doctoral Dissertation Award from China Simulation Federation, the Outstanding Graduation Project Supervisor Award from Beijing Higher Education Institutions, and the Xiaomi Young Scholar Award.

My research focuses on creating novel immersive XR experiences. I have published more than 30 papers and 20 artworks at the top international HCI/XR conferences.

â­ Looking for highly motivated students and research interns. æ‹›æ”¶ç¡•å£«ç”ŸåŠæš‘æœŸ/æ—¥å¸¸å­¦ç”Ÿç§‘ç ”ï¼Œæœ‰æ„è¯·è”ç³»æœ¬äººé‚®ç®±

# ğŸ‘©ğŸ»â€ğŸ« Teaching
- VR Interaction Design è™šæ‹Ÿç°å®äº¤äº’è®¾è®¡ï¼ˆæœ¬ç§‘ï¼‰
- Information Visualization Design ä¿¡æ¯å¯è§†åŒ–è®¾è®¡ï¼ˆæœ¬ç§‘ï¼‰
- Human-Computer Interaction and User Experience Design äººæœºäº¤äº’ä¸ç”¨æˆ·ä½“éªŒè®¾è®¡ï¼ˆç ”ç©¶ç”Ÿï¼‰
- Fundamentals of Digital Media Design æ•°å­—åª’ä½“è®¾è®¡åŸºç¡€ï¼ˆæœ¬ç§‘ï¼‰

# ğŸ§ª Research Foundations
- Humanities and Social Science Fund of Ministry of Education of China, Project: **XR-Based Intelligent Performance Perception Generation and Interaction Collaboration**(2022-2025) æ•™è‚²éƒ¨äººæ–‡ç¤¾ä¼šç§‘å­¦åŸºé‡‘è§„åˆ’é¡¹ç›®
- National Natural Science Foundation of China, Project: **Research on Affective Evaluation and Content-Based Adaptive Feedback for Intelligent Interactive Performance from Audience Perception**(2019-2021) å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é’å¹´é¡¹ç›®
- China National Arts Fund, Project: **Construction of Digital Promotion Platform for Intangible Culture Heritage (ICH) â€˜Hua erâ€™** (2018-2020) å›½å®¶è‰ºæœ¯åŸºé‡‘ä¼ æ’­æ¨å¹¿é¡¹ç›®
- National Key Research and Development Program of China, Project: **Yunnan Minority Dance Digital Performance Creativity and Display System Based on VR** (2019-2024) äº‘å—çœç§‘æŠ€å…é‡ç‚¹ç ”å‘é¡¹ç›®ï¼ˆå­è¯¾é¢˜ï¼‰
- Independent Project of the State Key Laboratory of Virtual Reality Technology and Systems, Project: **Research on Innovative Design of Immersive Performance under Human-AI Collaboration**(2024-2026) è™šæ‹Ÿç°å®æŠ€æœ¯ä¸ç³»ç»Ÿå…¨å›½é‡ç‚¹å®éªŒå®¤è‡ªä¸»è¯¾é¢˜

# ğŸ”” News 
- Dec, 2025 Â· SIGGRAPH ASIA Conference, ğŸ“HongKong, China
- Nov, 2025 Â· ICXR Conference <a href="https://icxr.net/2025/callForXRGallery.html">**XR Gallery Chair**</a>, ğŸ“Qingdao, China
- May, 2025 Â· CHI Conference, ğŸ“Yokohama, Japan

# ğŸ“– Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge2">IASDR 2025</div><div class="badge2">IASDR 2025</div><img src='images/matrix sheet.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**From Body to Interface: Co-design Gesture-based Interactions with Experts for Immersive Experiences**](https://iasdr2025.org/)

Zixiao Liu, **Shuo Yan**, Haiyan Jiang, Fengyi Yan and Henry Been-Lirn Duh

<a href="https://iasdr2025.org/" style="text-decoration: none; color: #00369F;">**To be published**</a>
- We developed a co-design framework and apply it to a foot-based interaction project exploring habitual foot actions as natural inputs for virtual-physical switching experience.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge2">IASDR 2025</div><div class="badge2">IASDR 2025</div><img src='images/mr.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Exploring and Co-Designing Typical Collaborative Scenarios in Mixed Reality: A Role-Based Approach**](https://iasdr2025.org/)

Fengyi Yan, **Shuo Yan**, Wensi Dai, Likun Zhao and Zixiao Liu

<a href="https://iasdr2025.org/" style="text-decoration: none; color: #00369F;">**To be published**</a>
- We proposed a comprehensive Role Interpretation Framework based on three core interpersonal dimensionsâ€”Dominance, Sociability, and Task Orientationâ€”to systematically capture and explain user roles in MR collaboration. 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CHI 2025</div><div class="badge">CHI 2025</div><img src='images/P1.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**"If My Apple Can Talk": Exploring the Use of Everyday Objects as Personalized AI Agents in Mixed Reality**](https://dl.acm.org/doi/full/10.1145/3706599.3720253)

Yu Wang, Yulu Lu, **Shuo Yan**, Xukun Shen

<a href="https://www.youtube.com/watch?v=FvPCVOcMXtc" style="text-decoration: none; color: #00369F;">**Video**</a>
- We developed the MyAIPal prototype system, which enables users to interact with AI agents of personalized everyday objects through voice dialogue and natural behaviors. 
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge1">ISMAR 2024</div><img src='images/beyondreality.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Beyond Realities: Designing Cross-Reality Interactions in the Immersive Narrative Experience**](https://ieeexplore.ieee.org/document/10765257)

Zixiao Liu, **Shuo Yan**, Wenjie He, Xiaomeng Wan, Xukun Shen

<a href="https://youtu.be/O6Cn66E263Y?si=XQUt2BcsvsAuqsQf" style="text-decoration: none; color: #00369F;">**Video**</a>
- We designed an immersive narrative â€œBeyond Realitiesâ€, and implemented four CR interactions in it: Portal Passthrough, Virtual Guidance, Object Passthrough, and Bystander Avatar.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge3">SIGGRAPH ASIA 2023</div><img src='images/achi.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**â€œAchi Mukua Experience Spaceâ€ â€”â€” A Multi-Player Immersive Experience of Yunnan ICH Dance**](https://dl.acm.org/doi/10.1145/3610591.3616431)

Siyu Luo, **Shuo Yan**

<a href="https://www.youtube.com/watch?v=HYASrRvVG4E" style="text-decoration: none; color: #00369F;">**Video**</a>
- We develops design methods for ICH dance that combine social presence, collaborative multiplayer interaction, and emotional feedback to enable the co-creation immersive experiences.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CHI 2023</div><img src='images/child.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**NoPhobiar: Designing A VR Game to Prevent Childhood Dark Phobia with Children and Stakeholders**](https://dl.acm.org/doi/10.1145/3544549.3585733)

XinyiÂ Su, **ShuoÂ Yan**

<a href="https://www.youtube.com/watch?v=bero8nW8BW8" style="text-decoration: none; color: #00369F;">**Video**</a>
- We developed a VR game for treating dark phobia in children aged 4-6 through participatory research involving children and stakeholders to identify design requirements.
</div>
</div>

# ğŸ˜ˆ XR Demos and Artworks

<div class='paper-box'><div class='paper-box-image'><div><div class="badge3">SIGGRAPH ASIA 2025</div><img src='images/hand.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Hands in Bloom: An Auditory-Accessible Immersive Experience Based on Chinese Sign Language Recognition and Gesture Tracking**]

Zhu Zhu, **Shuo Yan**

[**Video**](https://www.youtube.com/watch?v=HYASrRvVG4E) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- This project integrates Chinese Sign Language into immersive interaction, enhancing expressiveness and inclusivity while enabling barrier-free communication that bridges Deaf and hearing communities beyond natural gestures and instruction.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge3">SIGGRAPH ASIA 2025</div><img src='images/bamboo.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Bamboo Rhyme Craft: Immersive VR Bamboo Weaving through Coordinated Bimanual Gesture Interaction**](https://asia.siggraph.org/2025/)

Chenyue Zheng, Yaxuan Zhao, Runxin Guo, **Shuo Yan**

[**Video**](https://www.youtube.com/watch?v=HYASrRvVG4E) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
<a href="https://asia.siggraph.org/2025/" style="text-decoration: none; color: #00369F;">**To be published**</a>
- Immersive VR with coordinated bimanual gesture interaction revives traditional bamboo weaving, blending cultural heritage with engaging, hands-on experiences to promote, preserve, and creatively reinterpret intangible traditions for wider audiences.
</div>
</div>







# ğŸ† Honors and Awards
- 2024 Mentor Award,  
- 2023 Winner, Second Prize of Outstanding Innovation Cases of Aesthetic Education in Beijing Universitiesï¼ŒBeijing Education Commission
- 2023 Mentor Award, BUAA Excellent Master's Thesis BUAA
- 2022 Grant, $14000 Research Funding from Xiaomi Youth Scholarship Xiaomi
- 2022 Grant, $7000 Research Funding from Social Science Youth Scholarship BUAA
- 2021-2022 Mentor Award, Outstanding Undergraduate Graduation Design (Thesis)ï¼ŒBeijing Education Commission
- 2019 Winner, Third Prize of "Teaching Design" in the 7th National Collegiate and Universities Digital Art and Design Competition Ministry of Industry and Information Technology (MIIT)
- 2017 Winner, Outstanding Doctoral Dissertation Award of China Simulation Federation(CSF)
- 2015 Fellowship, National PhD Scholarship in China Ministry of Education of China

# ğŸ“š Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ’¬ Invited Talks
- 2025.11, [Research on Innovative Design of Human-Computer Collaborative Intelligent Performance](https://mp.weixin.qq.com/s/Im6Z4NIer50IrrRqCpHwpA), Dance Research Institute, China National Academy of Arts.  
- 2021.03, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)
- 2019.09, TEDxChengdu

