---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-SynXR Lab'></span>
The **SynXR (Synesthesia XR) Lab** explores Human-Computer Interaction (HCI) at the intersection of synesthetic experiences and performance art in extended reality (XR) environments. Through an interdisciplinary approach combining Design, Computer Science, Psychology, and Performing Arts, the lab investigates how multi-sensory integration and cross-reality interactions can enhance human perception, creativity, and artistic expression in digital spaces.

<span class='anchor' id='about-me'></span>

Hi, I am **Shuo Yan**, an Associate Professor at [School of New Media Art & Design](https://art.buaa.edu.cn/index.htm) / [State Key Laboratory of Virtual Reality Technology and Systems](https://vrlab.buaa.edu.cn/index.htm) in [Beihang University](https://www.buaa.edu.cn/). I received my Ph.D. in Intelligent Digital Performance from Beijing Institute of Technology, during which I was a visiting Ph.D. student in the Fluid Interfaces at [MIT Media Lab](https://www.media.mit.edu/). I received the Outstanding Doctoral Dissertation Award from China Simulation Federation, the Outstanding Graduation Project Supervisor Award from Beijing Higher Education Institutions, and the Xiaomi Young Scholar Award.

My research focuses on creating novel immersive XR experiences. I have published more than 30 papers and 10 artworks at the top international HCI/XR conferences.

â­ Looking for highly motivated students and research interns. æ‹›æ”¶ç¡•å£«ç”ŸåŠæš‘æœŸ/æ—¥å¸¸å­¦ç”Ÿç§‘ç ”ï¼Œæœ‰æ„è¯·è”ç³»æœ¬äººé‚®ç®±

# ğŸ‘©ğŸ»â€ğŸ« Teaching
- VR Interaction Design è™šæ‹Ÿç°å®äº¤äº’è®¾è®¡ï¼ˆæœ¬ç§‘ï¼‰
- Information Visualization Design ä¿¡æ¯å¯è§†åŒ–è®¾è®¡ï¼ˆæœ¬ç§‘ï¼‰
- Human-Computer Interaction and User Experience Design äººæœºäº¤äº’ä¸ç”¨æˆ·ä½“éªŒè®¾è®¡ï¼ˆç ”ç©¶ç”Ÿï¼‰
- Fundamentals of Digital Media Design æ•°å­—åª’ä½“è®¾è®¡åŸºç¡€ï¼ˆæœ¬ç§‘ï¼‰

# ğŸ”” News 
- Dec, 2025 Â· SIGGRAPH ASIA Conference, ğŸ“Hongkong, China
- Nov, 2025 Â· ICXR Conference <a href="https://icxr.net/2025/callForXRGallery.html">**XR Gallery Chair**</a>, ğŸ“Qingdao, China
- May, 2025 Â· CHI Conference, ğŸ“Yokohama, Japan

# ğŸ“– Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge2">IASDR 2025</div><div class="badge2">IASDR 2025</div><img src='images/matrix sheet.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**From Body to Interface: Co-design Gesture-based Interactions with Experts for Immersive Experiences**](https://iasdr2025.org/)

Zixiao Liu, **Shuo Yan**, Haiyan Jiang, Fengyi Yan and Henry Been-Lirn Duh

<a href="https://iasdr2025.org" style="text-decoration: none; color: #00369F;">**Video**</a>
<a href="https://iasdr2025.org/" style="text-decoration: none; color: #00369F;">**to be published**</a>
- We developed a co-design framework and apply it to a foot-based interaction project exploring habitual foot actions as natural inputs for virtual-physical switching experience.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge2">IASDR 2025</div><div class="badge2">IASDR 2025</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Exploring and Co-Designing Typical Collaborative Scenarios in Mixed Reality: A Role-Based Approach**](https://iasdr2025.org/)

Fengyi Yan, **Shuo Yan**, Wensi Dai, Likun Zhao and Zixiao Liu

<a href="https://iasdr2025.org" style="text-decoration: none; color: #00369F;">**Video**</a>
<a href="https://iasdr2025.org/" style="text-decoration: none; color: #00369F;">**to be published**</a>
- We proposed a comprehensive Role Interpretation Framework based on three core interpersonal dimensionsâ€”Dominance, Sociability, and Task Orientationâ€”to systematically capture and explain user roles in MR collaboration. 
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CHI 2025</div><div class="badge">CHI 2025</div><img src='images/P1.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**"If My Apple Can Talk": Exploring the Use of Everyday Objects as Personalized AI Agents in Mixed Reality**](https://dl.acm.org/doi/full/10.1145/3706599.3720253)

Yu Wang, Yulu Lu, **Shuo Yan**, Xukun Shen

<a href="https://www.youtube.com/watch?v=FvPCVOcMXtc" style="text-decoration: none; color: #00369F;">**Video**</a>
<a href="https://dl.acm.org/doi/full/10.1145/3706599.3720253" style="text-decoration: none; color: #00369F;">**Paper**</a>
- We developed the MyAIPal prototype system, which enables users to interact with AI agents of personalized everyday objects through voice dialogue and natural behaviors. 
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge1">ISMAR 2024</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**Beyond Realities: Designing Cross-Reality Interactions in the Immersive Narrative Experience**](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

Zixiao Liu, **Shuo Yan**, Wenjie He, Xiaomeng Wan, Xukun Shen

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
[**Paper**](https://dl.acm.org/doi/full/10.1145/3706599.3720253)
- We designed an immersive narrative â€œBeyond Realitiesâ€, and implemented four CR interactions in it: Portal Passthrough, Virtual Guidance, Object Passthrough, and Bystander Avatar.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge3">SIGGRAPH ASIA 2023</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="background-color: #EEB4B4; padding: 4px 8px; font-size: 11px; border-radius: 5px;">**Conference**</span>&nbsp;[**â€œAchi Mukua Experience Spaceâ€ â€”â€” A Multi-Player Immersive Experience of Yunnan ICH Dance**](https://dl.acm.org/doi/10.1145/3610591.3616431))

Siyu Luo, **Shuo Yan**

[**Video**](https://www.youtube.com/watch?v=HYASrRvVG4E) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
[**Paper**](https://dl.acm.org/doi/10.1145/3610591.3616431)
- We develops design methods for ICH dance that combine social presence, collaborative multiplayer interaction, and emotional feedback to enable the co-creation immersive experiences.
</div>
</div>









[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
[**Paper**](https://dl.acm.org/doi/full/10.1145/3706599.3720253)
- We designed an immersive narrative â€œBeyond Realitiesâ€, and implemented four CR interactions in it: Portal Passthrough, Virtual Guidance, Object Passthrough, and Bystander Avatar.
</div>
</div>

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
[**Paper**](https://dl.acm.org/doi/full/10.1145/3706599.3720253)
- We designed an immersive narrative â€œBeyond Realitiesâ€, and implemented four CR interactions in it: Portal Passthrough, Virtual Guidance, Object Passthrough, and Bystander Avatar.
</div>
</div>



- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# ğŸ† Honors and Awards
- 2024 Mentor Award,  
- 2023 Winner, Second Prize of Outstanding Innovation Cases of Aesthetic Education in Beijing Universitiesï¼ŒBeijing Education Commission
- 2023 Mentor Award, BUAA Excellent Master's Thesis BUAA
- 2022 Grant, $14000 Research Funding from Xiaomi Youth Scholarship Xiaomi
- 2022 Grant, $7000 Research Funding from Social Science Youth Scholarship BUAA
- 2021-2022 Mentor Award, Outstanding Undergraduate Graduation Design (Thesis)ï¼ŒBeijing Education Commission
- 2019 Winner, Third Prize of "Teaching Design" in the 7th National Collegiate and Universities Digital Art and Design Competition Ministry of Industry and Information Technology (MIIT)
- 2017 Winner, Outstanding Doctoral Dissertation Award of China Simulation Federation(CSF)
- 2015 Fellowship, National PhD Scholarship in China Ministry of Education of China

# ğŸ“– Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ’¬ Invited Talks
- 2025.11, [Research on Innovative Design of Human-Computer Collaborative Intelligent Performance](https://mp.weixin.qq.com/s/Im6Z4NIer50IrrRqCpHwpA), Dance Research Institute, China National Academy of Arts.  
- 2021.03, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)
- 2019.09, TEDxChengdu

# ğŸ’» Service
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
